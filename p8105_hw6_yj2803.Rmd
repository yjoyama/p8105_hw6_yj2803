---
title: "Homework 6"
author: "Yuki Joyama"
date: "2023-11-19"
output: github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

Read packages
```{r message=FALSE}
library(tidyverse)
library(modelr)
```

# Problem 1
```{r message=FALSE, warning=FALSE}
# read csv file
df_homicide = read_csv("./data/homicide-data.csv")

# modify the dataframe
df_homicide = df_homicide |> 
  mutate(
    city_state = paste(city, state, sep = ", "), # create a city_state variable
    victim_age = as.numeric(victim_age), # change victim_age from char to numeric
    homicide = if_else(
      disposition == "Closed without arrest" | disposition == "Open/No arrest", "unsolved","resolved"
    ),
    homicide = as.factor(homicide)
  ) |>
  filter(!(city_state %in% c("Dallas, TX", "Phoenix, AZ", "Kansas City, MO", "Tulsa, AL"))) |> # omit some cities due to the lack of data or data entry mistake
  filter(victim_race %in% c("White", "Black")) |> # limiting data to white or black
  filter(victim_sex != "Unknown") |> # exclude unknown sex
  drop_na(victim_age) # exclude unknown age
```

Logistic regression for crime outcome and victim age, sex and race in Baltimore, MD.

```{r}
# run logistic regression for Baltimore, MD
log_baltimore = df_homicide |> 
  filter(city_state == "Baltimore, MD") |> 
  glm(homicide ~ victim_age + victim_sex + victim_race, family = binomial, data = _) |> 
  broom::tidy()

log_baltimore

# check the level of the outcome variable
levels(pull(df_homicide, homicide))

# odds ratio for coef and 95% CI 
log_baltimore |> 
  filter(term == "victim_sexMale") |> 
  mutate(
    or = exp(estimate), # calculate odds ratio of the coefficients
    lb.or = exp(estimate - qnorm(.975) * std.error), # obtain the lower level of 95% CI
    ub.or = exp(estimate + qnorm(.975) * std.error) # obtain the upper level of 95% CI
  ) |> 
  select(or, lb.or, ub.or) |> 
  knitr::kable(digits = 2)
```

In Baltimore, MD, male victims have approximately 2.35 times the odds (95% CI: 1.79 - 3.08) of resolved cases than the unresolved cases compared to female victims when all other variables fixed.

Now run the logistic regression for each of the cities.
```{r}
# set up a function to get odds ratio for coef and 95% CI from logistic regression output
or_ci_glm = function(df){
  df |> 
    filter(term == "victim_sexMale") |> 
    mutate(
      or = exp(estimate),
      lb.or = exp(estimate - qnorm(.975) * std.error),
      ub.or = exp(estimate + qnorm(.975) * std.error)
    ) |> 
    select(or, lb.or, ub.or) 
}


case_log = df_homicide |>
  nest(df = -city_state) |> 
  mutate(
    log_model = purrr::map(df, \(df) glm(homicide ~ victim_age + victim_sex + victim_race, family = binomial, data = df)), # save logistic models for each city as list
    results = map(log_model, broom::tidy) # save logistic model results in tibble as list
  ) |>
  mutate(
    ors = map(results, or_ci_glm) # save odds ratios and 95%CI as list
  ) |> 
  unnest(ors) |> 
  select(city_state, or, lb.or, ub.or) 
  
# visualize the results
case_log |> 
  mutate(city_state = fct_reorder(city_state, or)) |> 
  ggplot(aes(x = city_state, y = or)) +
  geom_point() +
  geom_errorbar(aes(x = city_state, ymin = lb.or, ymax = ub.or)) +
  labs(
    title = "The odds ratios of resolved cases among male compared to female",
    x = "City",
    y = "Odds ratio"
  ) +
  theme_bw() +
  theme(axis.text.x = element_text(angle = 90)) 
```

From the plot, we can see that in Albuquerque, NM, the odds of cases to be solved is the lowest in male compared to female holding other variables (OR: `r case_log |> filter(city_state == "Albuquerque, NM") |> select(or) |> round(2)`, 95% CI: `r case_log |> filter(city_state == "Albuquerque, NM") |> select(lb.or) |> round(2)` - `r case_log |> filter(city_state == "Albuquerque, NM") |> select(ub.or) |> round(2)`). In New York, NY, the odds of resolved cases in male compared to female was the highest keeping all other variables fixed (OR: `r case_log |> filter(city_state == "New York, NY") |> select(or) |> round(2)`, 95% CI: `r case_log |> filter(city_state == "New York, NY") |> select(lb.or) |> round(2)` - `r case_log |> filter(city_state == "New York, NY") |> select(ub.or) |> round(2)`).

# Problem 2

```{r message=FALSE, cache=TRUE, warning=FALSE}
# download dataset for this question
weather_df = 
  rnoaa::meteo_pull_monitors(
    c("USW00094728"),
    var = c("PRCP", "TMIN", "TMAX"), 
    date_min = "2022-01-01",
    date_max = "2022-12-31") |>
  mutate(
    name = recode(id, USW00094728 = "CentralPark_NY"),
    tmin = tmin / 10,
    tmax = tmax / 10) |>
  select(name, id, everything())

# function to get sample
boot_sample = function(df) {
  sample_frac(df, replace = TRUE)
}

set.seed(1)

# get bootstrap samples
boot_strp = tibble(strp_num = 1:5000) |> 
  mutate(
    strp_sample = map(strp_num, \(i) boot_sample(weather_df))
  )

# fit linear regression model for each sample data 
boot_results = boot_strp |> 
  mutate(
    models = map(strp_sample, \(df) lm(tmax ~ tmin + prcp, data = df)),
    results_lm = map(models, broom::tidy),
    results_glance = map(models, broom::glance)
  ) |> 
  unnest(results_lm, results_glance) |> 
  select(strp_num, term, estimate, r.squared) |> 
  pivot_wider(names_from = term, values_from = estimate, names_prefix = "estimate_") |> 
  mutate(
    log_beta = log(estimate_tmin * estimate_prcp) # calculate log(beta1*beta2)
  )

# plot the distribution of estimates
boot_results |> 
  ggplot(aes(x = r.squared)) + 
  geom_density() +
  theme_bw()

boot_results |> 
  ggplot(aes(x = log_beta)) + 
  geom_density() +
  theme_bw()
```

The estimate of $r^2$ and $log(\hat{\beta}_1*\hat{\beta}_2)$ show left-skewed unimodal distribution. This indicates that there may be variability in the data.   
* 3361 out of 5000 $log(\hat{\beta}_1*\hat{\beta}_2)$ values were removed from the plot because the log of a negative number could not be calculated. 

The 95% confidence interval for $r^2$ is `r round(quantile(pull(boot_results, r.squared), 0.025), 2)` - `r round(quantile(pull(boot_results, r.squared), 0.975), 2)`; $log(\hat{\beta}_1*\hat{\beta}_2)$ is `r round(quantile(pull(boot_results, log_beta), 0.025, na.rm = T), 2)` - `r round(quantile(pull(boot_results, log_beta), 0.975, na.rm = T), 2)`.

# Problem 3
```{r message=FALSE}
# read csv file
df_birthwt = read_csv("./data/birthweight.csv")

# clean the data for regression analysis
df_birthwt = df_birthwt |> 
  mutate( # convert some variables from numeric to factor
    babysex = as.factor(babysex), 
    frace = as.factor(frace),
    malform = as.factor(malform),
    mrace = as.factor(mrace)
  ) |> 
  drop_na()
```

I will perform stepwise regression to build a model for this problem.

```{r}
# define intercept-only model
intercept_only = lm(bwt ~ 1, data = df_birthwt)

# define model with all predictors
all = lm(bwt ~ ., data = df_birthwt)

# perform both-direction stepwise regression
both = step(intercept_only, direction = 'both', scope = formula(all), trace = 0)

# final model
lm_birthwt = both 
lm_birthwt 
```

First, I fit the intercept-only model. Then, predictors were added to the model sequentially. After adding each predictor, any predictors that did not improve in model fit were removed from the model. This process was repeated until obtaining the final model.

The predictors included in the final model are:  
`bhead`, `blength`, `mrace`, `delwt`, `gaweeks`, `smoken`, `ppbmi`, `babysex`, `parity`, `ppwt`, `fincome`  

```{r}
# plot model residuals against fitted values
df_birthwt |> 
  add_predictions(lm_birthwt) |> 
  add_residuals(lm_birthwt) |> 
  ggplot(aes(x = pred, y = resid)) +
  geom_point(alpha = 0.2) +
  geom_hline(yintercept = 0, color = "red") +
  theme_bw() +
  labs(
    title = "Plot of Residuals vs. Predicted Values",
    x = "Predicted Values",
    y = "Residuals"
  ) 
```

We can see that the spread of the residuals are higher for the lower fitted values, but overall the points are scattered randomly around the residual = 0 line.  
